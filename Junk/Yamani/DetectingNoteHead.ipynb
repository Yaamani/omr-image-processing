{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_commonfunctions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_hough_lines(lines, shape, line_thickness):\n",
    "    lines_img = np.zeros(shape)\n",
    "    for l in lines:\n",
    "        x1 = l[0][0]\n",
    "        y1 = l[0][1]\n",
    "        x2 = l[1][0]\n",
    "        y2 = l[1][1]\n",
    "        #print(l)\n",
    "        #print(x1, y1, x2, y2)\n",
    "        cv2.line(lines_img, (x1,y1), (x2,y2), (255,255,255), line_thickness)\n",
    "\n",
    "    return lines_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def potential_staff_lines(note_img_thresh, staff_thickness):\n",
    "    DEG_TO_RAD = np.pi/180\n",
    "    width = note_img_thresh.shape[1]\n",
    "\n",
    "    # Hough to get potential staff lines\n",
    "    line_length = int(width/4)\n",
    "    lines = probabilistic_hough_line(note_img_thresh, threshold=10, line_length=line_length, line_gap=3, theta=np.arange(80*DEG_TO_RAD, 100*DEG_TO_RAD, 1*DEG_TO_RAD), seed=40)\n",
    "    lines_img_before_filteration = draw_hough_lines(lines, note_img_thresh.shape, 1)\n",
    "    lines_img_before_filteration = cv2.dilate(lines_img_before_filteration, np.ones((1, 11)))\n",
    "\n",
    "    # Get widest 5 contours/lines\n",
    "    lines_img = np.copy(lines_img_before_filteration)\n",
    "    image, contours, hierarchy = cv2.findContours(lines_img_before_filteration.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    contours_bounding_rectangles = []\n",
    "    for c in contours:\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "        #print(x, y, w, h)\n",
    "        contours_bounding_rectangles.append([c, [x, y, w, h]])\n",
    "\n",
    "    contours_bounding_rectangles_sorted = sorted(contours_bounding_rectangles, key = lambda x: x[1][2], reverse=True) # sort by width\n",
    "    contours_widest_5 = []\n",
    "    j = 5 if len(contours_bounding_rectangles_sorted) >= 5 else len(contours_bounding_rectangles_sorted)\n",
    "    for i in range(j):\n",
    "        contours_widest_5.append(contours_bounding_rectangles_sorted[i][0])\n",
    "\n",
    "    # Draw widest 5 contours/lines\n",
    "    lines_img = np.zeros(note_img_thresh.shape, dtype=np.uint8)\n",
    "    lines_img = rgb2gray(cv2.drawContours(gray2rgb(lines_img), contours_widest_5, -1, (255,255,255), 1))\n",
    "    k = 3\n",
    "    lines_img = my_close(lines_img, np.ones((k*staff_thickness, k*staff_thickness)))\n",
    "    lines_img = cv2.dilate(lines_img, np.ones((3, 3)))\n",
    "\n",
    "    # my_show_images([lines_img])\n",
    "\n",
    "    return lines_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_staff_lines(note_img_gray, staff_thickness):\n",
    "    # Otsu's thresholding\n",
    "    ret, note_img_thresh = cv2.threshold(note_img_gray, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    note_img_thresh = ~note_img_thresh\n",
    "\n",
    "    # Potential staff lines\n",
    "    potential_lines_img = potential_staff_lines(note_img_thresh, staff_thickness)\n",
    "    lines_img_flattened = (potential_lines_img > 0.5).T.flatten()\n",
    "    \n",
    "    # Iterate over each column to remove any \"run of white pixels\" with a length of \"m*staff_thickness\"\n",
    "    # But it must be a part from a potentail line to confirm removing (potential lines calculated above)\n",
    "    note_img_thresh_flattened = (note_img_thresh).T.flatten()\n",
    "    image, contours, hierarchy = cv2.findContours((note_img_thresh_flattened).astype(np.uint8), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for c in contours:\n",
    "        if c.shape == (2, 1, 2):\n",
    "            p1 = c[1][0][1]\n",
    "            p0 = c[0][0][1]\n",
    "            m = 2\n",
    "            if p1 - p0 <= staff_thickness*m:\n",
    "                #print(c)\n",
    "                staff_pixel_percentage = lines_img_flattened[p0:p1+1].sum() / len(lines_img_flattened[p0:p1+1])\n",
    "                if staff_pixel_percentage > 0.35:\n",
    "                    note_img_thresh_flattened[p0:p1+1] = 0\n",
    "        elif c.shape == (1, 1, 2):\n",
    "            #print(c)\n",
    "            p0 = c[0][0][1]\n",
    "            staff_pixel_percentage = lines_img_flattened[p0:p0+1].sum() / len(lines_img_flattened[p0:p0+1])\n",
    "            if staff_pixel_percentage > 0.35:\n",
    "                note_img_thresh_flattened[p0:p0+1] = 0\n",
    "\n",
    "\n",
    "    staff_lines_removed = note_img_thresh_flattened.reshape(note_img_thresh.T.shape).T\n",
    "\n",
    "\n",
    "    #my_show_images([note_img_gray, note_img_thresh, potential_lines_img, staff_lines_removed], dpi=80, row_max=5)\n",
    "\n",
    "\n",
    "    return staff_lines_removed, potential_lines_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_note_heads_contours(staff_lines_removed_masked):\n",
    "    thresh = cv2.adaptiveThreshold(255-staff_lines_removed_masked, 256, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 3, 1)\n",
    "    thresh = my_open(thresh, np.ones((7, 7)))\n",
    "    image, contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    my_area = thresh.shape[0]*thresh.shape[0]\n",
    "    contours_filtered = []\n",
    "    for c in contours:\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "        a = w*h\n",
    "        if 0.003 < a/my_area < 0.025: # test 1\n",
    "            if x > 0 and x+w < thresh.shape[1]: # test 2\n",
    "                (xc,yc), (d1,d2), angle = cv2.fitEllipse(c)\n",
    "                major_axis, minor_axis = max(d1,d2), min(d1,d2)\n",
    "                if major_axis/minor_axis <= 2.2: # test 3\n",
    "                    epsilon = 0.02*cv2.arcLength(c, True)\n",
    "                    approx = cv2.approxPolyDP(c, epsilon, True)\n",
    "                    #print(a/my_area, major_axis/minor_axis, len(approx))\n",
    "                    if len(approx) > 4: # test 4\n",
    "                        contours_filtered.append(c)\n",
    "\n",
    "    #contours_drawn = gray2rgb(np.copy(thresh))\n",
    "    #contours_drawn = cv2.drawContours(contours_drawn, contours_filtered, -1, (255, 0, 0), 2)\n",
    "    #contours_drawn = cv2.drawContours(contours_drawn, contours[2], -1, (255, 0, 0), 2)\n",
    "\n",
    "\n",
    "    #mask = cv2.dilate(contours_mask(contours_filtered, thresh.shape), np.ones((3, 3)))\n",
    "    mask = contours_mask(contours_filtered, thresh.shape)\n",
    "    image, contours_final, hierarchy = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    #print(len(contours_final))\n",
    "\n",
    "    #my_show_images([thresh, contours_drawn, mask], dpi=150, row_max=3)\n",
    "    return contours_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}